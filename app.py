# ğŸš€ ë‰´ìŠ¤íŒ©í† ë¦¬ - AI ê¸°ë°˜ ê¸°ì‚¬ ë¶„ì„ í”Œë«í¼ (konlpy ë²„ì „ + ìµœì í™”)
import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import re
import os
import time
import hashlib
from pathlib import Path
import requests
import pickle
import json
from collections import Counter, defaultdict
import subprocess
import sys

# Java í™˜ê²½ë³€ìˆ˜ ì„¤ì • (konlpy ì‚¬ìš© ì „)
if not os.environ.get("JAVA_HOME"):
    os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-11-openjdk-amd64"

# konlpy importëŠ” í™˜ê²½ë³€ìˆ˜ ì„¤ì • í›„ì—
from konlpy.tag import Okt
okt = Okt()

# ë¨¸ì‹ ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ import
def safe_import():
    """ê°œì„ ëœ ì•ˆì „í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import"""
    global TfidfVectorizer, cosine_similarity
    try:
        from sklearn.feature_extraction.text import TfidfVectorizer
        from sklearn.metrics.pairwise import cosine_similarity
        st.success("âœ… ë¨¸ì‹ ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì„±ê³µ")
    except ImportError:
        st.warning("âš ï¸ scikit-learnì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        TfidfVectorizer = None
        cosine_similarity = None

safe_import()

# êµ¬ê¸€ ì‹œíŠ¸ ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ
try:
    from google_sheets_utils_deploy import (
        load_data_from_google_sheets_cached,
        preprocess_dataframe,
        get_connection_status
    )
    SHEETS_UTILS_AVAILABLE = True
except ImportError:
    SHEETS_UTILS_AVAILABLE = False

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ğŸš€ ë‰´ìŠ¤íŒ©í† ë¦¬",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì „ì—­ ì„¤ì •
PERPLEXITY_API_KEY = st.secrets["PERPLEXITY_API_KEY"]
APP_PASSWORD = st.secrets["APP_PASSWORD"]

# ìºì‹œ ì„¤ì •
CACHE_DIR = Path("cache")
CACHE_DIR.mkdir(exist_ok=True)
API_CACHE_DIR = CACHE_DIR / "api_calls"
API_CACHE_DIR.mkdir(exist_ok=True)

# CSS ìŠ¤íƒ€ì¼
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #1e3c72, #2a5298);
        color: white;
        padding: 1rem;
        border-radius: 10px;
        margin-bottom: 2rem;
    }
    .feature-card {
        background: #f8f9fa;
        padding: 1.5rem;
        border-radius: 10px;
        border-left: 4px solid #007bff;
        margin: 1rem 0;
    }
    .success-box {
        background: #d4edda;
        border: 1px solid #c3e6cb;
        border-radius: 5px;
        padding: 1rem;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# ================================
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# ================================
def initialize_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    if 'data_loaded' not in st.session_state:
        st.session_state.data_loaded = False
    if 'main_df' not in st.session_state:
        st.session_state.main_df = None
    if 'last_update' not in st.session_state:
        st.session_state.last_update = None
    if 'login_status' not in st.session_state:
        st.session_state.login_status = False

# ================================
# ìºì‹± ì‹œìŠ¤í…œ
# ================================
def save_to_cache(key, data):
    """ìºì‹œì— ë°ì´í„° ì €ì¥"""
    try:
        cache_file = API_CACHE_DIR / f"{key}.pkl"
        cache_data = {
            'data': data,
            'timestamp': time.time(),
            'date': datetime.now().strftime("%Y-%m-%d")
        }
        with open(cache_file, 'wb') as f:
            pickle.dump(cache_data, f)
        return True
    except Exception as e:
        st.error(f"ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        return False

def load_from_cache(key, max_age_hours=24):
    """ìºì‹œì—ì„œ ë°ì´í„° ë¡œë“œ"""
    try:
        cache_file = API_CACHE_DIR / f"{key}.pkl"
        if not cache_file.exists():
            return None
        
        with open(cache_file, 'rb') as f:
            cache_data = pickle.load(f)
        
        # ìºì‹œ ìœ íš¨ì„± ê²€ì‚¬
        cache_age = time.time() - cache_data['timestamp']
        if cache_age > max_age_hours * 3600:
            return None
        
        return cache_data['data']
    except:
        return None

# ================================
# ë°ì´í„° ë¡œë”© í•¨ìˆ˜ (ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬ ê°•í™”)
# ================================
def load_data_with_session_management(force_refresh=False):
    """ì„¸ì…˜ ìƒíƒœë¥¼ í™œìš©í•œ ë°ì´í„° ë¡œë”©"""
    # ì´ë¯¸ ë¡œë“œëœ ë°ì´í„°ê°€ ìˆê³  ê°•ì œ ìƒˆë¡œê³ ì¹¨ì´ ì•„ë‹Œ ê²½ìš°
    if not force_refresh and st.session_state.data_loaded and st.session_state.main_df is not None:
        st.info("ğŸ’¾ ì €ì¥ëœ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return st.session_state.main_df
    
    # ìƒˆë¡œìš´ ë°ì´í„° ë¡œë“œ
    with st.spinner("ğŸ“Š êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ ë°ì´í„° ë¡œë”© ì¤‘..."):
        if SHEETS_UTILS_AVAILABLE:
            df = load_data_from_google_sheets_cached(force_refresh=force_refresh)
            if not df.empty:
                df = preprocess_dataframe(df)
                # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                st.session_state.main_df = df
                st.session_state.data_loaded = True
                st.session_state.last_update = datetime.now()
                st.success(f"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ: {len(df)}ê°œ ê¸°ì‚¬")
                return df
            else:
                st.error("âŒ êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return pd.DataFrame()
        else:
            st.error("âŒ êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ëª¨ë“ˆì´ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()

# ================================
# API í˜¸ì¶œ
# ================================
def call_perplexity_api_cached(prompt, model="sonar-pro", max_age_hours=24):
    """ìºì‹±ëœ Perplexity API í˜¸ì¶œ"""
    try:
        # ìºì‹œ í‚¤ ìƒì„±
        cache_key = hashlib.md5(f"{prompt}_{model}".encode()).hexdigest()
        
        # ìºì‹œì—ì„œ ë¨¼ì € í™•ì¸
        cached_result = load_from_cache(cache_key, max_age_hours)
        if cached_result:
            st.info("ğŸ”„ ìºì‹œì—ì„œ AI ë¶„ì„ ê²°ê³¼ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
            return cached_result
        
        # API í˜¸ì¶œ
        headers = {
            "Authorization": f"Bearer {PERPLEXITY_API_KEY}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": model,
            "messages": [
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ë‰´ìŠ¤ ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ê¸°ì‚¬ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ í•µì‹¬ íŠ¸ë Œë“œì™€ ì¤‘ìš”í•œ í‚¤ì›Œë“œë¥¼ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "temperature": 0.3,
            "max_tokens": 1000
        }
        
        response = requests.post(
            "https://api.perplexity.ai/chat/completions",
            headers=headers,
            json=data,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            api_result = result["choices"][0]["message"]["content"]
            
            # ê²°ê³¼ë¥¼ ìºì‹œì— ì €ì¥
            save_to_cache(cache_key, api_result)
            st.success("ğŸ†• ìƒˆë¡œìš´ AI ë¶„ì„ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
            return api_result
        else:
            st.error(f"API ì˜¤ë¥˜: {response.status_code}")
            return None
            
    except Exception as e:
        st.error(f"API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
        return None

# ================================
# í•µì‹¬ ë¶„ì„ ê¸°ëŠ¥ë“¤
# ================================
def generate_today_review(df, industry="ì „ì²´"):
    """ğŸ“Š ì˜¤ëŠ˜ì˜ ë¦¬ë·° - ë‹¹ì¼ ì£¼ìš” ê¸°ì‚¬ ì¢…í•© ë¶„ì„"""
    if df.empty:
        return "ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    # ì—…ê³„ í•„í„°ë§
    filtered_df = df if industry == "ì „ì²´" else df[df["ì—…ê³„"] == industry]
    if filtered_df.empty:
        return "í•´ë‹¹ ì—…ê³„ì˜ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    # ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ì¤€ ìµœê·¼ ê¸°ì‚¬ë“¤ ì„ ë³„
    today = datetime.now()
    current_month = today.month
    
    # ì´ë²ˆ ë‹¬ ê¸°ì‚¬ë“¤ë§Œ í•„í„°ë§
    if 'ì›”' in filtered_df.columns:
        current_month_articles = filtered_df[filtered_df['ì›”'] == f"{current_month}ì›”"]
    else:
        current_month_articles = filtered_df
    
    # ìƒìœ„ ê°€ì¤‘ì¹˜ ê¸°ì‚¬ë“¤ ì„ ë³„
    top_articles = current_month_articles.nlargest(15, 'ì „ì²´ê°€ì¤‘ì¹˜')
    
    # ê¸°ì‚¬ í…ìŠ¤íŠ¸ ì •ë¦¬
    review_texts = []
    for _, article in top_articles.iterrows():
        title = article.get('ì œëª©', '')
        content = article.get('ì£¼ìš”ë‚´ìš©', '')
        media = article.get('ë§¤ì²´', '')
        if pd.notna(title):
            review_texts.append(f"[{media}] {title}\nìš”ì•½: {str(content)[:200]}")
    
    if not review_texts:
        return "ë¶„ì„í•  ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    prompt = f"""
    ë‹¹ì‹ ì€ ê²½í—˜ ë§ì€ ë‰´ìŠ¤ ì—ë””í„°ì…ë‹ˆë‹¤. 
    ì˜¤ëŠ˜ì˜ ì£¼ìš” ë‰´ìŠ¤ë“¤ì„ ì¢…í•©í•˜ì—¬ 'ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤ ë¦¬ë·°'ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
    
    [ë¶„ì„ ëŒ€ìƒ: {industry} ì—…ê³„]
    
    ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:
    
    ## ğŸ“Š ì˜¤ëŠ˜ì˜ í•µì‹¬ ì´ìŠˆ
    - ì£¼ìš” ì´ìŠˆ 3ê°€ì§€ë¥¼ ê°„ê²°í•˜ê²Œ ì •ë¦¬
    
    ## ğŸ“ˆ ì£¼ëª©í•  íŠ¸ë Œë“œ
    - ì˜¤ëŠ˜ ê¸°ì‚¬ë“¤ì—ì„œ ë°œê²¬ëœ íŠ¸ë Œë“œ ë¶„ì„
    
    ## ğŸ” ì‹¬ì¸µ ë¶„ì„ í¬ì¸íŠ¸
    - ì¶”ê°€ ì£¼ëª©í•´ì•¼ í•  ì§€ì ë“¤
    
    ## ğŸ“‹ ë‚´ì¼ ì£¼ëª©í•  í‚¤ì›Œë“œ
    - í–¥í›„ ê´€ë ¨ ê¸°ì‚¬ì—ì„œ ì£¼ëª©í•  í‚¤ì›Œë“œë“¤
    
    ê¸°ì‚¬ ëª©ë¡:
    {chr(10).join(review_texts)}
    """
    
    return call_perplexity_api_cached(prompt, max_age_hours=6)

def generate_weekly_monthly_review(df, period_type="ì£¼ì°¨", target_period=None):
    """ğŸ—“ï¸ ì›”Â·ì£¼ì°¨ ë¦¬ë·° - ê¸°ê°„ë³„ íŠ¸ë Œë“œ ì¢…í•© ë¶„ì„"""
    if df.empty:
        return "ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    if period_type == "ì›”":
        if target_period and "ì›”" in df.columns:
            period_data = df[df["ì›”"] == target_period]
            period_name = target_period
        else:
            # í˜„ì¬ ì›” ë°ì´í„°
            current_month = f"{datetime.now().month}ì›”"
            period_data = df[df["ì›”"] == current_month] if "ì›”" in df.columns else df
            period_name = current_month
    else:  # ì£¼ì°¨
        if target_period and "ì£¼ì°¨" in df.columns:
            period_data = df[df["ì£¼ì°¨"] == target_period]
            period_name = target_period
        else:
            # ìµœê·¼ ì£¼ì°¨ ë°ì´í„°
            if "ì£¼ì°¨" in df.columns:
                latest_week = df["ì£¼ì°¨"].dropna().iloc[-1] if not df["ì£¼ì°¨"].dropna().empty else "ì´ë²ˆì£¼"
                period_data = df[df["ì£¼ì°¨"] == latest_week]
                period_name = latest_week
            else:
                period_data = df
                period_name = "ì´ë²ˆ ê¸°ê°„"
    
    if period_data.empty:
        return f"{period_name} ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    # ì£¼ìš” ê¸°ì‚¬ë“¤ ì„ ë³„
    top_articles = period_data.nlargest(20, 'ì „ì²´ê°€ì¤‘ì¹˜')
    
    # ë§¤ì²´ë³„ ë¶„í¬ ë¶„ì„
    media_distribution = period_data['ë§¤ì²´'].value_counts().head(5)
    
    # ì—…ê³„ë³„ ë¶„í¬ ë¶„ì„
    industry_distribution = period_data['ì—…ê³„'].value_counts().head(5)
    
    # í…ìŠ¤íŠ¸ ì •ë¦¬
    article_texts = []
    for _, article in top_articles.iterrows():
        title = article.get('ì œëª©', '')
        media = article.get('ë§¤ì²´', '')
        industry = article.get('ì—…ê³„', '')
        if pd.notna(title):
            article_texts.append(f"[{media}|{industry}] {title}")
    
    prompt = f"""
    ë‹¹ì‹ ì€ ë‰´ìŠ¤ íŠ¸ë Œë“œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    {period_name}ì˜ ë‰´ìŠ¤ ë™í–¥ì„ ì¢…í•© ë¶„ì„í•˜ì—¬ ìƒì„¸í•œ ë¦¬ë·°ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
    
    ## ğŸ“Š {period_name} ë¦¬ë·° ë¦¬í¬íŠ¸
    
    ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:
    
    ### ğŸ¯ ì£¼ìš” ì´ìŠˆ Top 3
    - ì´ ê¸°ê°„ì˜ ê°€ì¥ ì¤‘ìš”í•œ ì´ìŠˆ 3ê°€ì§€
    
    ### ğŸ“ˆ íŠ¸ë Œë“œ ë¶„ì„
    - ì£¼ëª©í•  ë§Œí•œ íŠ¸ë Œë“œì™€ ë³€í™”
    
    ### ğŸ“° ë§¤ì²´ë³„ íŠ¹ì§•
    - ì£¼ìš” ë§¤ì²´ë“¤ì˜ ë³´ë„ ê²½í–¥ ë¶„ì„
    
    ### ğŸ¢ ì—…ê³„ë³„ ë™í–¥
    - ì—…ê³„ë³„ ì£¼ìš” ë‰´ìŠ¤ íŠ¹ì§•
    
    ### ğŸ”® í–¥í›„ ì „ë§
    - ë‹¤ìŒ ê¸°ê°„ ì£¼ëª©í•  í¬ì¸íŠ¸
    
    [ë¶„ì„ ë°ì´í„°]
    - ì´ ê¸°ì‚¬ ìˆ˜: {len(period_data)}ê°œ
    - ì£¼ìš” ë§¤ì²´: {', '.join(media_distribution.index[:3])}
    - ì£¼ìš” ì—…ê³„: {', '.join(industry_distribution.index[:3])}
    
    ì£¼ìš” ê¸°ì‚¬ ëª©ë¡:
    {chr(10).join(article_texts)}
    """
    
    return call_perplexity_api_cached(prompt, max_age_hours=12)

def generate_custom_analysis(df, keywords, industry="ì „ì²´", analysis_type="ì¢…í•©"):
    """ğŸ¯ ë§ì¶¤ ë¶„ì„ - í‚¤ì›Œë“œ ê¸°ë°˜ ì‹¬ì¸µ ë¶„ì„"""
    if df.empty or not keywords:
        return "ë¶„ì„í•  ë°ì´í„°ë‚˜ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤."
    
    # ì—…ê³„ í•„í„°ë§
    filtered_df = df if industry == "ì „ì²´" else df[df["ì—…ê³„"] == industry]
    if filtered_df.empty:
        return "í•´ë‹¹ ì—…ê³„ì˜ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    # í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬
    if isinstance(keywords, str):
        keyword_list = [k.strip() for k in keywords.split(',')]
    else:
        keyword_list = keywords
    
    # í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê¸°ì‚¬ë“¤ í•„í„°ë§
    keyword_articles = []
    for _, article in filtered_df.iterrows():
        title = str(article.get('ì œëª©', '')).lower()
        content = str(article.get('ì£¼ìš”ë‚´ìš©', '')).lower()
        combined_text = f"{title} {content}"
        
        # í‚¤ì›Œë“œ ë§¤ì¹­ í™•ì¸
        matches = sum(1 for keyword in keyword_list if keyword.lower() in combined_text)
        if matches > 0:
            article_dict = article.to_dict()
            article_dict['keyword_matches'] = matches
            keyword_articles.append(article_dict)
    
    if not keyword_articles:
        return f"'{', '.join(keyword_list)}' í‚¤ì›Œë“œì™€ ê´€ë ¨ëœ ê¸°ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    # í‚¤ì›Œë“œ ë§¤ì¹­ ìˆ˜ì™€ ê°€ì¤‘ì¹˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    keyword_articles.sort(key=lambda x: (x['keyword_matches'], x.get('ì „ì²´ê°€ì¤‘ì¹˜', 0)), reverse=True)
    
    # ìƒìœ„ ê¸°ì‚¬ë“¤ ì„ ë³„
    top_keyword_articles = keyword_articles[:15]
    
    # ë¶„ì„ìš© í…ìŠ¤íŠ¸ ì¤€ë¹„
    analysis_texts = []
    for article in top_keyword_articles:
        title = article.get('ì œëª©', '')
        media = article.get('ë§¤ì²´', '')
        matches = article.get('keyword_matches', 0)
        if title:
            analysis_texts.append(f"[{media}] {title} (ë§¤ì¹­: {matches}ê°œ)")
    
    # ë¶„ì„ íƒ€ì…ë³„ í”„ë¡¬í”„íŠ¸
    if analysis_type == "íŠ¸ë Œë“œ":
        analysis_focus = "ì‹œê°„ì˜ íë¦„ì— ë”°ë¥¸ í‚¤ì›Œë“œ ê´€ë ¨ íŠ¸ë Œë“œ ë³€í™”ì™€ í–¥í›„ ì „ë§"
    elif analysis_type == "ë§¤ì²´ë¹„êµ":
        analysis_focus = "ë§¤ì²´ë³„ ë³´ë„ ê´€ì ê³¼ ë…¼ì¡°ì˜ ì°¨ì´ì  ë¶„ì„"
    elif analysis_type == "ì˜í–¥ë¶„ì„":
        analysis_focus = "í•´ë‹¹ í‚¤ì›Œë“œê°€ ì—…ê³„ì™€ ì‚¬íšŒì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ë¶„ì„"
    else:  # ì¢…í•©
        analysis_focus = "í‚¤ì›Œë“œ ê´€ë ¨ ì¢…í•©ì ì¸ í˜„í™©ê³¼ ì˜ë¯¸ ë¶„ì„"
    
    prompt = f"""
    ë‹¹ì‹ ì€ ë‰´ìŠ¤ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    '{', '.join(keyword_list)}' í‚¤ì›Œë“œì— ëŒ€í•œ ë§ì¶¤í˜• ì‹¬ì¸µ ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”.
    
    [ë¶„ì„ ì¡°ê±´]
    - ëŒ€ìƒ ì—…ê³„: {industry}
    - ë¶„ì„ íƒ€ì…: {analysis_type}
    - ë¶„ì„ ì´ˆì : {analysis_focus}
    - ê´€ë ¨ ê¸°ì‚¬ ìˆ˜: {len(keyword_articles)}ê°œ
    
    ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:
    
    ## ğŸ¯ í‚¤ì›Œë“œ ë¶„ì„: {', '.join(keyword_list)}
    
    ### ğŸ“Š í˜„í™© ê°œìš”
    - í‚¤ì›Œë“œ ê´€ë ¨ ì£¼ìš” ì´ìŠˆ ì •ë¦¬
    
    ### ğŸ” ì‹¬ì¸µ ë¶„ì„
    - {analysis_focus}
    
    ### ğŸ“ˆ ì£¼ìš” ë°œê²¬ì‚¬í•­
    - ë¶„ì„ì„ í†µí•´ ë°œê²¬í•œ í•µì‹¬ ì¸ì‚¬ì´íŠ¸
    
    ### ğŸ’¡ ì‹œì‚¬ì 
    - í•´ë‹¹ í‚¤ì›Œë“œì˜ ì˜ë¯¸ì™€ í–¥í›„ ê´€ì‹¬ í¬ì¸íŠ¸
    
    ### ğŸ”® í›„ì† ê´€ì°° í¬ì¸íŠ¸
    - ê³„ì† ì§€ì¼œë´ì•¼ í•  ê´€ë ¨ ì´ìŠˆë“¤
    
    ë¶„ì„ ëŒ€ìƒ ê¸°ì‚¬:
    {chr(10).join(analysis_texts)}
    """
    
    return call_perplexity_api_cached(prompt, max_age_hours=8)

# ================================
# ë¡œê·¸ì¸ í•¨ìˆ˜
# ================================
def login():
    """ë¡œê·¸ì¸ ì²˜ë¦¬"""
    st.title("ğŸ” ë‰´ìŠ¤íŒ©í† ë¦¬ ë¡œê·¸ì¸")
    
    password = st.text_input("ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password")
    
    if st.button("ë¡œê·¸ì¸", key="login_button"):
        if password == APP_PASSWORD:
            st.session_state.login_status = True
            st.success("âœ… ë¡œê·¸ì¸ ì„±ê³µ!")
            st.rerun()
        else:
            st.error("âŒ ë¹„ë°€ë²ˆí˜¸ê°€ í‹€ë ¸ìŠµë‹ˆë‹¤.")

# ================================
# ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
# ================================
def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜"""
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    initialize_session_state()
    
    # ë¡œê·¸ì¸ í™•ì¸
    if not st.session_state.login_status:
        login()
        return
    
    # í—¤ë”
    st.markdown("""
    <div class="main-header">
        <h1>ğŸš€ ë‰´ìŠ¤íŒ©í† ë¦¬</h1>
        <p>AI ê¸°ë°˜ ê¸°ì‚¬ ë¶„ì„ í”Œë«í¼</p>
        <p>âœ¨ konlpy ê¸°ë°˜ í•œêµ­ì–´ ì²˜ë¦¬ ì‹œìŠ¤í…œ</p>
    </div>
    """, unsafe_allow_html=True)
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("ğŸ”§ ì œì–´íŒ")
        
        # ë°ì´í„° ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼
        if st.button("ğŸ”„ ë°ì´í„° ìƒˆë¡œê³ ì¹¨", key="refresh_data_button"):
            st.session_state.data_loaded = False
            st.session_state.main_df = None
            st.rerun()
        
        # ë°ì´í„° ë¡œë“œ ìƒíƒœ í‘œì‹œ
        if st.session_state.data_loaded and st.session_state.last_update:
            st.success(f"ğŸ“Š ë°ì´í„° ë¡œë“œë¨")
            st.info(f"ğŸ•’ ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {st.session_state.last_update.strftime('%Y-%m-%d %H:%M:%S')}")
        
        # êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ìƒíƒœ
        if SHEETS_UTILS_AVAILABLE:
            connection_status = get_connection_status()
            if connection_status['connected']:
                st.success("âœ… êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²°ë¨")
            else:
                st.error(f"âŒ êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì‹¤íŒ¨: {connection_status['message']}")
    
    # ë°ì´í„° ë¡œë“œ
    df = load_data_with_session_management()
    
    if df.empty:
        st.error("âŒ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ë©”ì¸ ê¸°ëŠ¥ íƒ­
    tab1, tab2, tab3 = st.tabs([
        "ğŸ“Š ì˜¤ëŠ˜ì˜ ë¦¬ë·°", "ğŸ—“ï¸ ì›”Â·ì£¼ì°¨ ë¦¬ë·°", "ğŸ¯ ë§ì¶¤ ë¶„ì„"
    ])
    
    with tab1:
        st.markdown("""
        <div class="feature-card">
            <h3>ğŸ“Š ì˜¤ëŠ˜ì˜ ë¦¬ë·°</h3>
            <p>ë‹¹ì¼ ì£¼ìš” ê¸°ì‚¬ë“¤ì„ ì¢…í•© ë¶„ì„í•˜ì—¬ í•µì‹¬ ì´ìŠˆì™€ íŠ¸ë Œë“œë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤.</p>
        </div>
        """, unsafe_allow_html=True)
        
        # ì—…ê³„ ì„ íƒ
        industries = ['ì „ì²´'] + sorted(df['ì—…ê³„'].unique().tolist())
        selected_industry = st.selectbox("ì—…ê³„ ì„ íƒ", industries, key="today_review_industry")
        
        if st.button("ğŸ“Š ì˜¤ëŠ˜ì˜ ë¦¬ë·° ìƒì„±", use_container_width=True, key="generate_today_review"):
            with st.spinner("ğŸ¤– AIê°€ ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤ë¥¼ ì¢…í•© ë¶„ì„í•˜ëŠ” ì¤‘..."):
                today_review = generate_today_review(df, selected_industry)
            
            st.markdown("### ğŸ“Š ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤ ë¦¬ë·°")
            st.markdown(today_review)
    
    with tab2:
        st.markdown("""
        <div class="feature-card">
            <h3>ğŸ—“ï¸ ì›”Â·ì£¼ì°¨ ë¦¬ë·°</h3>
            <p>íŠ¹ì • ê¸°ê°„ì˜ ë‰´ìŠ¤ ë™í–¥ì„ ì¢…í•© ë¶„ì„í•˜ì—¬ íŠ¸ë Œë“œ ë¦¬í¬íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.</p>
        </div>
        """, unsafe_allow_html=True)
        
        # ê¸°ê°„ íƒ€ì… ì„ íƒ
        col1, col2 = st.columns(2)
        with col1:
            period_type = st.selectbox("ë¶„ì„ ê¸°ê°„", ["ì£¼ì°¨", "ì›”"], key="period_type_select")
        with col2:
            if period_type == "ì›”" and "ì›”" in df.columns:
                available_months = sorted(df["ì›”"].dropna().unique().tolist())
                target_period = st.selectbox("ì›” ì„ íƒ", ["í˜„ì¬ ì›”"] + available_months, key="target_month_select")
                if target_period == "í˜„ì¬ ì›”":
                    target_period = None
            elif period_type == "ì£¼ì°¨" and "ì£¼ì°¨" in df.columns:
                available_weeks = sorted(df["ì£¼ì°¨"].dropna().unique().tolist())
                target_period = st.selectbox("ì£¼ì°¨ ì„ íƒ", ["ìµœê·¼ ì£¼ì°¨"] + available_weeks, key="target_week_select")
                if target_period == "ìµœê·¼ ì£¼ì°¨":
                    target_period = None
            else:
                target_period = None
                st.info("í•´ë‹¹ ê¸°ê°„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        if st.button("ğŸ—“ï¸ ê¸°ê°„ë³„ ë¦¬ë·° ìƒì„±", use_container_width=True, key="generate_period_review"):
            with st.spinner(f"ğŸ¤– AIê°€ {period_type} ë¦¬ë·°ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘..."):
                period_review = generate_weekly_monthly_review(df, period_type, target_period)
            
            st.markdown(f"### ğŸ—“ï¸ {period_type} ë¦¬ë·° ë¦¬í¬íŠ¸")
            st.markdown(period_review)
    
    with tab3:
        st.markdown("""
        <div class="feature-card">
            <h3>ğŸ¯ ë§ì¶¤ ë¶„ì„</h3>
            <p>íŠ¹ì • í‚¤ì›Œë“œë‚˜ ì£¼ì œì— ëŒ€í•œ ì‹¬ì¸µ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.</p>
        </div>
        """, unsafe_allow_html=True)
        
        # ë¶„ì„ ì„¤ì •
        col1, col2 = st.columns(2)
        with col1:
            # ì—…ê³„ ì„ íƒ
            industries = ['ì „ì²´'] + sorted(df['ì—…ê³„'].unique().tolist())
            selected_industry = st.selectbox("ì—…ê³„ ì„ íƒ", industries, key="custom_analysis_industry")
            
            # ë¶„ì„ íƒ€ì… ì„ íƒ
            analysis_type = st.selectbox(
                "ë¶„ì„ ìœ í˜•", 
                ["ì¢…í•©", "íŠ¸ë Œë“œ", "ë§¤ì²´ë¹„êµ", "ì˜í–¥ë¶„ì„"], 
                key="analysis_type_select"
            )
        
        with col2:
            # í‚¤ì›Œë“œ ì…ë ¥
            keywords_input = st.text_input(
                "ë¶„ì„ í‚¤ì›Œë“œ", 
                placeholder="ì˜ˆ: ì¸ê³µì§€ëŠ¥, ì „ê¸°ì°¨, ë°”ì´ì˜¤ (ì‰¼í‘œë¡œ êµ¬ë¶„)",
                key="custom_keywords_input"
            )
            
            # í‚¤ì›Œë“œ ê°œìˆ˜ í‘œì‹œ
            if keywords_input:
                keyword_count = len([k.strip() for k in keywords_input.split(',') if k.strip()])
                st.info(f"ì…ë ¥ëœ í‚¤ì›Œë“œ: {keyword_count}ê°œ")
        
        # ë¶„ì„ ì‹¤í–‰
        if keywords_input:
            if st.button("ğŸ¯ ë§ì¶¤ ë¶„ì„ ì‹¤í–‰", use_container_width=True, key="execute_custom_analysis"):
                keywords_list = [k.strip() for k in keywords_input.split(',') if k.strip()]
                
                with st.spinner(f"ğŸ¤– AIê°€ '{', '.join(keywords_list)}' í‚¤ì›Œë“œë¥¼ ì‹¬ì¸µ ë¶„ì„í•˜ëŠ” ì¤‘..."):
                    custom_analysis_result = generate_custom_analysis(
                        df, keywords_list, selected_industry, analysis_type
                    )
                
                st.markdown("### ğŸ¯ ë§ì¶¤ ë¶„ì„ ê²°ê³¼")
                st.markdown(custom_analysis_result)
        else:
            if st.button("ğŸ¯ ë§ì¶¤ ë¶„ì„ ì‹¤í–‰", use_container_width=True, key="execute_custom_analysis_empty"):
                st.warning("âš ï¸ ë¶„ì„í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    main()
